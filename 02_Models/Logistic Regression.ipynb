{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0wx9/H83qv14qlm+ue0l+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6EyL6osMST2U"},"source":["# Logistic Regression\r\n","\r\n","Logistic regression, despite its name, is a classification algorithm rather than regression algorithm. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating the probability of occurrence of an event using its logistics function."]},{"cell_type":"code","metadata":{"id":"jGUXcHm1TNrB"},"source":["# importing numpy\r\n","import numpy as np\r\n","\r\n","# importing Linear regression model\r\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KA8B2ui8TAR2"},"source":["## Example "]},{"cell_type":"markdown","metadata":{"id":"S6E22NXiTAR3"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"QzJD7nixTAR3"},"source":["# dataset\r\n","from sklearn.datasets import load_iris\r\n","\r\n","# loading dataset\r\n","X, Y = load_iris(return_X_y = True)\r\n","\r\n","# printing to see elements\r\n","print('X values : \\n', X[:5])\r\n","print('Y values : \\n', Y[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_NyWv2GTAR3"},"source":["### Creating a Train test split"]},{"cell_type":"code","metadata":{"id":"nNyZja9xTAR3"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.4, random_state = 1 )\r\n","\r\n","# printing size of train and test data\r\n","\r\n","print('X_train : ', X_train.shape)\r\n","print('X_test : ', X_test.shape)\r\n","\r\n","print('Y_train : ', Y_train.shape)\r\n","print('Y_test : ', Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pf_bRf9eTAR4"},"source":["### Creating an Logistic regression Object\r\n","\r\n","**\"solver\"** parameter represents which algorithm to use in the optimization problem. \r\n","\r\n","* liblinear − It is a good choice for small datasets. It also handles L1 penalty. For multiclass problems, it is limited to one-versus-rest schemes.\r\n","\r\n","* newton-cg − It handles only L2 penalty.\r\n","\r\n","* lbfgs − For multiclass problems, it handles multinomial loss. It also handles only L2 penalty.\r\n","\r\n","* saga − It is a good choice for large datasets. For multiclass problems, it also handles multinomial loss. Along with L1 penalty, it also supports ‘elasticnet’ penalty.\r\n","\r\n","* sag − It is also used for large datasets. For multiclass problems, it also handles multinomial loss."]},{"cell_type":"code","metadata":{"id":"7xqLKNqBTAR4"},"source":["# we can also add penalty\r\n","LR = LogisticRegression(random_state=0, solver = 'lbfgs')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rjWD53HDTAR4"},"source":["### Train model on training dataset"]},{"cell_type":"code","metadata":{"id":"g7DR9o7MTAR4"},"source":["LR.fit(X_train, Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1POqx66VTzcW"},"source":["### Prediction using the trained model"]},{"cell_type":"code","metadata":{"id":"fWwq4sUWTzcX"},"source":["Y_pred = LR.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dOSqShdTzcY"},"source":["print('Coefficients: \\n', LR.coef_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LAKxBDsTzca"},"source":["### Accuracy\r\n"]},{"cell_type":"code","metadata":{"id":"8WAqMkQTTzcb"},"source":["# accuracy \r\n","print('Accuracy on Train : ', round(LR.score(X_train, Y_train)*100, 2))\r\n","print('Accuracy on Test : ', round(LR.score(X_test, Y_test)*100, 2))\r\n","print('Accuracy on Whole Dataset : ', round(LR.score(X, Y)*100, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hU8CYnLr6EPE"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"-CicL77o6DmJ"},"source":["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n","\r\n","# Confusion Matrix \r\n","result = confusion_matrix(Y_test, Y_pred)\r\n","print(\"Confusion Matrix:\")\r\n","print(result)\r\n","\r\n","# Classification report\r\n","result1 = classification_report(Y_test, Y_pred)\r\n","print(\"\\nClassification Report:\")\r\n","print (result1)\r\n","\r\n","# Accuracy score\r\n","result2 = accuracy_score(Y_test, Y_pred)\r\n","print(\"\\nAccuracy:\",result2)"],"execution_count":null,"outputs":[]}]}