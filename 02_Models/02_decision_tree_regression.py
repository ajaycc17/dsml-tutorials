# -*- coding: utf-8 -*-
"""Decision_Regressor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ydSMcXd9XUTdsP5gMP3ajYjqTmFFg-v
"""

import pandas as pd

import numpy as np

from sklearn.tree import DecisionTreeRegressor

from sklearn.ensemble import RandomForestRegressor

df  = pd.read_csv('Boston.csv')

print(df)

print(df.shape)

print(df.isnull().sum())

print(df.info())

y = df['medv']

X = df.drop('medv', axis=1)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .30, random_state=1)

from sklearn.tree import DecisionTreeRegressor

dtr = DecisionTreeRegressor(random_state = 1)

dtr.fit(X_train,y_train)

print(dtr.score(X_test,y_test))

parameters={"splitter":["best","random"],
            "max_depth" : [1,5],
           "min_samples_leaf":[1,2,3,4,5,6,7,8,9,10],
           "max_features":["auto","log2","sqrt"], #auto and None work the same
           "max_leaf_nodes":[None,10,20,30,40] }



tuning_model=GridSearchCV(dtr,param_grid=parameters,scoring='neg_mean_squared_error',cv=3,verbose=0)

tuning_model.fit(X_train,y_train)

print(tuning_model.best_params_)
print(tuning_model.best_estimator_.score(X_test,y_test))

"""Random Forest Regressor"""

from sklearn.model_selection import GridSearchCV

param_grid = {  'bootstrap': [True], 'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}

rfr = RandomForestRegressor(random_state = 1)

g_search = GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)

g_search.fit(X_train, y_train);

print(g_search.best_params_)

print(g_search.best_estimator_.score(X_test,y_test))

