{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Naive Bayes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOq1GN8QmXR93gbzuxVAA7m"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WYGeKWQQ1thF"},"source":["# Naive Bayes Calssifier\r\n","\r\n","Naïve Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with a strong assumption that all the predictors are independent to each other i.e. the presence of a feature in a class is independent to the presence of any other feature in the same class."]},{"cell_type":"markdown","metadata":{"id":"Ivry4tpi2DbH"},"source":["**1. Gaussian Naïve Bayes**\r\n","Gaussian Naïve Bayes classifier assumes that the data from each label is drawn from a simple Gaussian distribution.\r\n","\r\n","**2.\tMultinomial Naïve Bayes**\r\n","It assumes that the features are drawn from a simple Multinomial distribution.\r\n","\r\n","**3.\tBernoulli Naïve Bayes**\r\n","The assumption in this model is that the features binary (0s and 1s) in nature. An application of Bernoulli Naïve Bayes classification is Text classification with ‘bag of words’ model\r\n","\r\n","**4.\tComplement Naïve Bayes**\r\n","It was designed to correct the severe assumptions made by Multinomial Bayes classifier. This kind of NB classifier is suitable for imbalanced data sets"]},{"cell_type":"code","metadata":{"id":"6oHrPJS51XmD"},"source":["from sklearn.model_selection import train_test_split\r\n","from sklearn.naive_bayes import GaussianNB"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3nu8-xW15PF"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"mvdjRYF32SF0"},"source":["from sklearn.datasets import load_breast_cancer\r\n","\r\n","data = load_breast_cancer()\r\n","\r\n","# feature and label name\r\n","feature_names = data['feature_names']\r\n","label_names = data['target_names']\r\n","print(feature_names, '\\n',label_names)\r\n","\r\n","# data\r\n","X = data['data']\r\n","Y = data['target']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_NyWv2GTAR3"},"source":["### Creating a Train test split"]},{"cell_type":"code","metadata":{"id":"nNyZja9xTAR3"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.4, random_state = 1 )\r\n","\r\n","# printing size of train and test data\r\n","\r\n","print('X_train : ', X_train.shape)\r\n","print('X_test : ', X_test.shape)\r\n","\r\n","print('Y_train : ', Y_train.shape)\r\n","print('Y_test : ', Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2jGJSRPV3PaW"},"source":["# Classifier"]},{"cell_type":"code","metadata":{"id":"0D3TwBXh3MY8"},"source":["# GNB Classifier\r\n","GNB = GaussianNB()\r\n","\r\n","# training\r\n","GNB.fit(X_train, Y_train)\r\n","\r\n","# predictions\r\n","Y_pred = GNB.predict(X_test)\r\n","\r\n","# accuracy\r\n","acc = GNB.score(X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaudKVpf3lCb"},"source":["acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hU8CYnLr6EPE"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"-CicL77o6DmJ"},"source":["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n","\r\n","# Confusion Matrix \r\n","result = confusion_matrix(Y_test, Y_pred)\r\n","print(\"Confusion Matrix:\")\r\n","print(result)\r\n","\r\n","# Classification report\r\n","result1 = classification_report(Y_test, Y_pred)\r\n","print(\"\\nClassification Report:\")\r\n","print (result1)\r\n"," \r\n","# Accuracy score\r\n","result2 = accuracy_score(Y_test, Y_pred)\r\n","print(\"\\nAccuracy:\",result2)"],"execution_count":null,"outputs":[]}]}