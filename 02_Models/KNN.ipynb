{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqE5WXB5u6QCgN2rydjSUi"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xPqSJs5Vtbav"},"source":["# K-Nearest Neighbors\r\n","\r\n","One of the simplest machine learning algorithms, is non-parametric and lazy in nature. Non-parametric means that there is no assumption for the underlying data distribution i.e. the model structure is determined from the dataset. Lazy or instance-based learning means that for the purpose of model generation, it does not require any training data points and whole training data is used in the testing phase."]},{"cell_type":"code","metadata":{"id":"QDS4XPL1tZIr"},"source":["from sklearn.neighbors import NearestNeighbors\r\n","from sklearn.neighbors import KNeighborsRegressor\r\n","\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RETC2ZFuttmv"},"source":["# Unsupervised KNN"]},{"cell_type":"markdown","metadata":{"id":"rGit4zskvmOJ"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"kCQnNa0Et9rw"},"source":["data = np.array([[-1, 1], [-2, 2], [-3, 3], [1, 2], [2, 3], [3, 4],[4, 5]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5E8w7BCVvpxU"},"source":["## KNN on data"]},{"cell_type":"code","metadata":{"id":"vhJZ0ku4uFG9"},"source":["nrst_neigh = NearestNeighbors(n_neighbors = 3, algorithm='ball_tree')\r\n","nrst_neigh.fit(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cp-nX-rovum0"},"source":["## Distances and Indices of data points"]},{"cell_type":"code","metadata":{"id":"RXznUrcsuLkf"},"source":["distances, indices = nrst_neigh.kneighbors(data)\r\n","print(indices, '\\n\\n', distances)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUTnmUlrv1J4"},"source":["## K-Neighbors graphs"]},{"cell_type":"code","metadata":{"id":"iuKq0yNtuNml"},"source":["nrst_neigh.kneighbors_graph(data).toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8A4rGSdv_N0"},"source":["# Supervised KNN"]},{"cell_type":"markdown","metadata":{"id":"pYPPm29Lpzgj"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"QzJD7nixTAR3"},"source":["# dataset\r\n","from sklearn.datasets import load_iris\r\n","\r\n","# loading dataset\r\n","X, Y = load_iris(return_X_y = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_NyWv2GTAR3"},"source":["### Creating a Train test split"]},{"cell_type":"code","metadata":{"id":"nNyZja9xTAR3"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.4, random_state = 1 )\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4D7AMlFwSTe"},"source":["### Scaling"]},{"cell_type":"code","metadata":{"id":"7ThKGG6LwWIZ"},"source":["from sklearn.preprocessing import StandardScaler\r\n","scaler = StandardScaler()\r\n","scaler.fit(X_train)\r\n","X_train = scaler.transform(X_train)\r\n","X_test = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z3XI2iGwwYt_"},"source":["### KNN training"]},{"cell_type":"code","metadata":{"id":"AlwECS_owgZ1"},"source":["knnr = KNeighborsRegressor(n_neighbors = 8)\r\n","knnr.fit(X_train, Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LAKxBDsTzca"},"source":["### Accuracy\r\n"]},{"cell_type":"code","metadata":{"id":"8WAqMkQTTzcb"},"source":["# accuracy \r\n","print('Accuracy on Train : ', round(knnr.score(X_train, Y_train)*100, 2))\r\n","print('Accuracy on Test : ', round(knnr.score(X_test, Y_test)*100, 2))"],"execution_count":null,"outputs":[]}]}