{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Introduction and Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+hMzeB5HJjCqgCbS0a+cX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NUvxVNn-2Xkh"},"source":["# Scikit Learn (Sklearn)\r\n","\r\n","Scikit-learn (Sklearn) is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib."]},{"cell_type":"code","metadata":{"id":"mEMix1tX2OGr"},"source":["# installing sklearn\r\n","\r\n","! pip install scikit-learn\r\n","# ! pip install -U scikit-learn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-8Bilvq27Ek"},"source":["# importing sklearn\r\n","import sklearn\r\n","\r\n","# importing a dataset from sklearn (iris dataset)\r\n","from sklearn.datasets import load_iris # flower dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yjDT-K1w3w7F"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"id":"ybZV2f4J3t6c"},"source":["# load data\r\n","iris = load_iris()\r\n","\r\n","# the feature values and labels/Tags\r\n","X = iris.data\r\n","Y = iris.target\r\n","\r\n","# feature name and label name\r\n","feature_names = iris.feature_names\r\n","target_names = iris.target_names\r\n","\r\n","print(\"Feature names:\", feature_names)\r\n","print(\"Target names:\", target_names)\r\n","\r\n","print(\"\\nFirst 10 rows of X:\\n\", X[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oFYPftsA4zns"},"source":["# Train-test split"]},{"cell_type":"code","metadata":{"id":"RZZdfQac42hG"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.3, random_state = 1 )\r\n","\r\n","# printing size of train and test data\r\n","\r\n","print('X_train : ', X_train.shape)\r\n","print('X_test : ', X_test.shape)\r\n","\r\n","print('Y_train : ', Y_train.shape)\r\n","print('Y_test : ', Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqHSD-Ze6BA3"},"source":["# Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"I_aCdpjW6Enu"},"source":["### Binarization\r\n","\r\n","This preprocessing technique is used when we need to convert our numerical values into Boolean values."]},{"cell_type":"code","metadata":{"id":"ugtKxGKR6Dou"},"source":["import numpy as np\r\n","from sklearn import preprocessing\r\n","\r\n","data = np.array(\r\n","  [[2.1, -1.9, 5.5],\r\n","   [-1.5, 2.4, 3.5],\r\n","   [0.5, -7.9, 5.6],\r\n","   [5.9, 2.3, -5.8]]\r\n",")\r\n","\r\n","data_binarized = preprocessing.Binarizer(threshold=0.5).transform(data)\r\n","print(\"\\nBinarized data:\\n\", data_binarized)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGkyrmAO6vwW"},"source":["### Mean removal\r\n","\r\n","This technique is used to eliminate the mean from feature vector so that every feature centered on zero."]},{"cell_type":"code","metadata":{"id":"vqLmc2AO6zTB"},"source":["data_scaled = preprocessing.scale(data, )\r\n","\r\n","print(\"Mean_removed =\", data_scaled)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGJGW8CK8KOy"},"source":["### Scaling\r\n","\r\n","We use this preprocessing technique for scaling the feature vectors. Scaling of feature vectors is important, because the features should not be synthetically large or small."]},{"cell_type":"code","metadata":{"id":"-bzRB59s8Pri"},"source":["# defining min max scaler parameters\r\n","data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))\r\n","\r\n","# using it to scale data\r\n","scaled_minmax = data_scaler_minmax.fit_transform(data)\r\n","\r\n","# printing the scaled data\r\n","print (\"\\nMin max scaled data:\\n\", data_scaled_minmax)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gSQhosXG8_Ub"},"source":["### Normalising\r\n","* L1 Normalisation :\r\n","It is also called Least Absolute Deviations. It modifies the value in such a manner that the sum of the absolute values remains always up to 1 in each row. Following example shows the implementation of L1 normalisation on input data.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"RaDHZ4QS9WFv"},"source":["data_normalized_l1 = preprocessing.normalize(data, norm='l1')\r\n","print(\"\\nL1 normalized data:\\n\", data_normalized_l1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txRWzImQ9W4j"},"source":["* L2 Normalisation :\r\n","Also called Least Squares. It modifies the value in such a manner that the sum of the squares remains always up to 1 in each row. Following example shows the implementation of L2 normalisation on input data."]},{"cell_type":"code","metadata":{"id":"0RHdb0vN9Xtv"},"source":["data_normalized_l2 = preprocessing.normalize(data, norm='l2')\r\n","print(\"\\nL1 normalized data:\\n\", data_normalized_l2)"],"execution_count":null,"outputs":[]}]}