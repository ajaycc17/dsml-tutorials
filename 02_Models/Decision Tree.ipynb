{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Decision Tree.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNA7z2/B9LM72QqCN+XCk8X"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dLZBLzT-2O9z"},"source":["# Decision Tree\r\n","\r\n","Decisions tress (DTs) are the most powerful non-parametric supervised learning method. They can be used for the classification and regression tasks. The main goal of DTs is to create a model predicting target variable value by learning simple decision rules deduced from the data features. Decision trees have two main entities; one is root node, where the data splits, and other is decision nodes or leaves, where we get final output."]},{"cell_type":"code","metadata":{"id":"oQaSLwEA1-cR"},"source":["from sklearn import tree"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bdIXMljt2-C3"},"source":["## Classifier"]},{"cell_type":"markdown","metadata":{"id":"S6E22NXiTAR3"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"QzJD7nixTAR3"},"source":["# dataset\r\n","from sklearn.datasets import load_iris\r\n","\r\n","# loading dataset\r\n","X, Y = load_iris(return_X_y = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_NyWv2GTAR3"},"source":["### Creating a Train test split"]},{"cell_type":"code","metadata":{"id":"nNyZja9xTAR3"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.4, random_state = 1 )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKJo7th92oqj"},"source":["### Train and test"]},{"cell_type":"code","metadata":{"id":"ibLaQlSk2pLl"},"source":["DT = tree.DecisionTreeClassifier()\r\n","DT.fit(X_train, Y_train)\r\n","Y_pred = DT.predict(X_test)\r\n","acc = DT.score(X_test, Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixE3gbG23IGt"},"source":["acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bak3Bij83c9a"},"source":["## Regression"]},{"cell_type":"code","metadata":{"id":"_Mvh0aqmLjF_"},"source":["# dataset\r\n","from sklearn.datasets import load_diabetes\r\n","\r\n","# loading dataset\r\n","X, Y = load_diabetes(return_X_y=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZznIx14Mnrc"},"source":["### Creating a Train test split"]},{"cell_type":"code","metadata":{"id":"5rgr4s6gNS7O"},"source":["# importing train test split\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# creating a train-test split\r\n","X_train, X_test, Y_train, Y_test = train_test_split( X, Y, \r\n","                    test_size = 0.4, random_state = 1 )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tyqwid2g38gd"},"source":["DTT = tree.DecisionTreeRegressor()\r\n","DTT.fit(X_train, Y_train)\r\n","Y_pred = DTT.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ez1U-LnL4hUu"},"source":["from sklearn.metrics import mean_squared_error, r2_score\r\n","\r\n","# The mean squared error\r\n","print('Mean squared error: %.2f'\r\n","      % mean_squared_error(Y_test, Y_pred))\r\n","\r\n","# The coefficient of determination: 1 is perfect prediction\r\n","print('\\nCoefficient of determination: %.2f'\r\n","      % r2_score(Y_test, Y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-8C7tufFLRD"},"source":["# if coefficient of determination is negative then the model is a poor fit for the data."],"execution_count":null,"outputs":[]}]}